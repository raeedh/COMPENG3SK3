\documentclass[12pt]{article}
\usepackage[letterpaper, margin=1in]{geometry}

% \usepackage[dvipsnames]{xcolor}
% \usepackage{xcolor}

\usepackage{graphicx}
\usepackage{subcaption}
\graphicspath{{./figures/}}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,   
    urlcolor=blue,
}

\usepackage{parskip}
\usepackage{amsmath}
\usepackage{titlesec}

% \usepackage{listings}
\usepackage[numbered, framed]{matlab-prettifier}
\usepackage[ruled,lined,linesnumbered]{algorithm2e}

\usepackage{tikzscale}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\pgfplotsset{
    compat = newest,
    % width=5cm,
    % height=4cm,
}

\titleformat*{\section}{\large\bfseries}
%\allowdisplaybreaks

% remove vertical spacing above top figure
\makeatletter
\setlength{\@fptop}{0pt}
\makeatother
%

% \renewcommand{\thesubsection}{\thesection.\alph{subsection}}

\title{COMPENG 3SK3 Project 2 Report}
\author{
    Raeed Hassan \\
    hassam41 \\
}

\begin{document}

\maketitle
\clearpage

\section*{MATLAB Implementation}
The documented code for the MATLAB implementation of Newton's method is implemented in \texttt{project2.m}. The function implementing Newton's method is shown below in Listing~\ref{list:newton}.

\begin{lstlisting}[style=Matlab-editor, caption={MATLAB Implementation of Newton's Method}, label={list:newton}]
%% Implement the Newton's method based denoising algorithm
function p_est = newtons(init_scheme, alpha, N, K, lambda, max_iterations)
    p_est = zeros(N,3);

    %% Load data
    % load distances, d (dist)
    load('data for student/dist_R5_L40_N100_K21.mat','dist');
    % load LiDAR observation positions, q (pts_o)
    load('data for student/observation_R5_L40_N100_K21.mat','pts_o');
    % load LiDAR measurements, p (pts_markers)
    load('data for student/pts_R5_L40_N100_K21.mat','pts_markers');

    for i = 1:N
        %% extract coordinates, distances for marker and set appropriate p, d, q values
        p_hat = squeeze(pts_markers(:,i,:));
        d = dist(i,:);
        q = pts_o;

        %% initalize value of p(0)
        switch init_scheme
            case 'mean'
                p0 = p0_init_mean(p_hat);
            case 'first'
                p0 = p0_init_first(p_hat);
            case 'random'
                p0 = p0_init_random;
        end
        
        p = p0.';

        for j = 1:max_iterations
        r = zeros(K,1);
        J = zeros(K,3);

        %% Calculate and update iteration
        for k = 1:K
            % Calculate r and J
            r(k) = norm(p-q(k,:).') - d(k);
            
            J(k,:) = [...
            (p(1) - q(k,1).') / (r(k) + d(k)),...
            (p(2) - q(k,2).') / (r(k) + d(k)), ...
            (p(3) - q(k,3).') / (r(k) + d(k))];

        end
        % Calculate g and H
        g = (J.' * r) + (lambda * sum(2*(p.'-p_hat)).');
        H = (J.' * J) + (2*lambda*K*eye(3));

        % Update iteration
        p = p - alpha*inv(H)*g;
        end

        p_est(i,:) = p;
    end
end
\end{lstlisting}

\section*{Pseudo Code}
The pseudo code describing all the necessary details of the Newton's method implementation is shown in Algorithm~\ref{algo:pseudo}.


\begin{algorithm}[H]
    Initialize variables\;
    Load data\;

    \SetKwData{Maxiterations}{max\_iterations}
    \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

    \Input{$\{\mathbf{\hat{p}}_{\text{ik}}\}_{i=1,k=1}^{N,K}$, $\{d_{\text{ik}}\}_{i=1,k=1}^{N,K}$, $\{\mathbf{q}_{\text{k}}\}_{k=1}^{K}$}
    \Output{$\{\mathbf{\tilde{p}}_{\text{i}}\}_{i=1}^{N}$}

    \For{$i \gets 1$ \KwTo N}{
        Extract measured coordinates and distances corresponding to the i-th marker\;
        
        Initialize starting position $\text{p}^{(0)}$\;

        \For{$j \gets 1$ \KwTo \Maxiterations}{
            Calculate vector of residuals, $\mathbf{r}$, and the Jacobian matrix, $\mathbf{J}$\;
            Calculate gradient of the loss function, $\mathbf{g}$, and Hessian matrix of loss function, $\mathbf{H}$\;
            Calculate descent direction for Newton's method\;
            Update the coordinate of the i-th marker according to the Newton's method\;
            
        }

        Record $\mathbf{\tilde{p}}_\text{i}$\;
    }
    \caption{Newton's method based denoising algorithm}
    \label{algo:pseudo}
\end{algorithm}

\section*{Root Mean Square Error (RSME)}
The quality of the estimated coordinates of markers was evaluated by computing the RSME between the estimated coordinates and the ground-truth markers with the formula below:

\begin{equation}
    \text{RSME} = \sqrt{\frac{1}{N} \sum_{i=1}^{N} \lVert \mathbf{\tilde{p}}_\text{i} - \mathbf{p}_\text{i} \rVert_2^2} 
\end{equation}

The RSME was calculated in MATLAB with the function shown in Listing~\ref{list:rsme}.

\begin{lstlisting}[style=Matlab-editor, caption={MATLAB Implementation of RSME}, label={list:rsme}]
function val = RSME(p_est, N)
    % load ground-truth oordinates, (pts_marks_gt)
    load('data for student/gt_R5_L40_N100_K21.mat','pts_marks_gt');

    val = sqrt((1/N) * norm(p_est - pts_marks_gt)^2);
end
\end{lstlisting}

\subsection*{Fine-tune $\lambda$}
To determine the optimal $\lambda$, $\lambda_{op}$, we change the value of $\lambda$ when $\mathbf{p}^{(0)}$ is the average of the $K$ measured coordinates to reduce the RMSE after 50 iterations of Newton's method. We observe that lower value of $\lambda$ is, the lower the converged RSME is. We select $\lambda = 10^{-4}$ as $\lambda_{op}$ as continuing to decrease $\lambda$ any further results in a negligible reduction in the RSME.

\begin{filecontents}[overwrite]{./figures/lambda.tikz}
\begin{tikzpicture}
    \begin{axis}[
        % title = {RSME vs. $\lambda$},
        width = \textwidth,
        %height = 150,
        xmin = 0.01, xmax = 100,
        xmode = log,
        % ymin = 0, ymax = 0.04,
        ylabel = Real Mean Square Error (RSME), xlabel = $\lambda$ relative to $\lambda_{op}$,
        yticklabel style={
            /pgf/number format/fixed,
            /pgf/number format/precision=2
        },
        scaled y ticks=false,
        xticklabel style={
            /pgf/number format/fixed,
            /pgf/number format/precision=3
        },
        scaled x ticks=false,
        legend pos = north east,
    ]

    \addplot table [y=rsme, x=lambda] {./data/lambda.dat};
    \end{axis}
\end{tikzpicture}
\end{filecontents}

\begin{figure}[htp]
    \centering
    \caption{RSME against $\lambda$}
    \label{fig:lambda}
    \includegraphics[width=0.92\textwidth]{lambda.tikz}
\end{figure}

\subsection*{Fine-tune the initialization $\mathbf{p}^{(0)}$}

The curves of RSME against iterations given three different initialization schemes at $\lambda = \lambda_{op} = 10^{-4}$ are shown below. Figure~\ref{fig:rsme_mean} shows the RSME against iterations given $\mathbf{p}^{(0)}$ is the average of the $K$ measured coordinates. Figure~\ref{fig:rsme_first} shows the RSME against iterations given $\mathbf{p}^{(0)}$ is the first measured coordinate. Figure~\ref{fig:rsme_randn} shows the RSME against iterations given $\mathbf{p}^{(0)}$ is a normally distributed random vector.

The number of iterations needed varies depending on the chosen initialization scheme. When $\mathbf{p}^{(0)}$ is the average of the $K$ measured coordinates, we observe the initial error (RSME) to be relatively close to the converged value, and quickly converges within 20 iterations. When selecting the first measured coordinate instead, we see more iterations are needed to converge and initial error is larger (nearly an order of magnitude larger), but the final converged error is similar. Similarly, when switching to a normally distributed random vector for the initialization scheme we observe the number of iterations needed for convergence and the initial error both increase significantly (again increasing by an order of magnitude from the previous scheme), while the final converged error is similar.

We can conclude that the converged RSME will be similar regardless of the initialization scheme used, however the number of iterations required for convergence and the initial RSME will vary depending on the scheme.  

\begin{filecontents}[overwrite]{./figures/rsme_mean.tikz}
\begin{tikzpicture}
    \begin{axis}[
        title = {RSME vs. Number of Iterations},
        width = \textwidth,
        %height = 150,
        xmin = 0, xmax = 100,
        ymin = 0, ymax = 0.04,
        ylabel = Real Mean Square Error (RSME), xlabel = Number of Iterations,
        yticklabel style={
        /pgf/number format/fixed,
        /pgf/number format/precision=3
        },
        scaled y ticks=false,
        legend pos = north east,
    ]

    \addplot table [y=rsme_mean, x=max_iterations] {./data/rsme.dat};
    \end{axis}
\end{tikzpicture}
\end{filecontents}

\begin{filecontents}[overwrite]{./figures/rsme_first.tikz}
\begin{tikzpicture}
    \begin{axis}[
        title = {RSME vs. Number of Iterations},
        width = \textwidth,
        %height = 150,
        xmin = 0, xmax = 100,
        ymin = 0, ymax = 0.25,
        ylabel = Real Mean Square Error (RSME), xlabel = Number of Iterations,
        yticklabel style={
        /pgf/number format/fixed,
        /pgf/number format/precision=3
        },
        scaled x ticks=false,
        legend pos = north east,
    ]

    \addplot table [y=rsme_first, x=max_iterations] {./data/rsme.dat};
    % \addlegendentry{Choose First Measured Coordinates}

    \end{axis}
\end{tikzpicture}
\end{filecontents}

\begin{filecontents}[overwrite]{./figures/rsme_randn.tikz}
\begin{tikzpicture}
    \begin{axis}[
        title = {RSME vs. Number of Iterations},
        width = \textwidth,
        %height = 150,
        xmin = 0, xmax = 100,
        ymin = 0, ymax = 25,
        ylabel = Real Mean Square Error (RSME), xlabel = Number of Iterations,
        yticklabel style={
        /pgf/number format/fixed,
        /pgf/number format/precision=3
        },
        scaled x ticks=false,
        legend pos = north east,
    ]

    \addplot table [y=rsme_randn, x=max_iterations] {./data/rsme.dat};
    % \addlegendentry{Set as Normally Distributed Random Vector}

    \end{axis}
\end{tikzpicture}
\end{filecontents}

\begin{figure}[htp]
    \centering
    \caption{RSME against Iterations for Different Initialization Schemes}
    \begin{subfigure}[b]{0.62\textwidth}
        \caption{RSME for Average of Measured Coordinates}
        \label{fig:rsme_mean}
        \includegraphics[width=\textwidth]{rsme_mean.tikz}
    \end{subfigure}
    \begin{subfigure}[b]{0.62\textwidth}
        \caption{RSME for First of Measured Coordinates}
        \label{fig:rsme_first}
        \includegraphics[width=\textwidth]{rsme_first.tikz}
    \end{subfigure}
    \begin{subfigure}[b]{0.62\textwidth}
        \caption{RSME for Normally Distributed Random Vector}
        \label{fig:rsme_randn}
        \includegraphics[width=\textwidth]{rsme_randn.tikz}
    \end{subfigure}
\end{figure}

% \begin{figure}[htp]
%     \centering
%     \caption{RSME for Average of Measured Coordinates}
%     \label{fig:rsme_mean}
%     \includegraphics[width=\textwidth]{rsme_mean.tikz}
% \end{figure}

% \begin{figure}[htp]
%     \centering
%     \caption{RSME for First of Measured Coordinates}
%     \label{fig:rsme_first}
%     \includegraphics[width=\textwidth]{rsme_first.tikz}
% \end{figure}

% \begin{figure}[htp]
%     \centering
%     \caption{RSME for Normally Distributed Random Vector}
%     \label{fig:rsme_randn}
%     \includegraphics[width=\textwidth]{rsme_randn.tikz}
% \end{figure}

\end{document}